blockMeansTbl <- merge(reshape(allTblSDs, v.names = c("A", "C"), idvar = "SESSION_ID", timevar = "blockPairs", direction = "wide", sep = ""),
reshape(blockMeans, v.names = c("M", "N"), idvar = "SESSION_ID", timevar = "BLOCK_NAME", direction = "wide", sep = ""),
by = "SESSION_ID")
fooFun <- function(myData, sessionID, blockName, trialBlocks, trialLatency, trialError, vError, vExtreme, vStd){
names(myData)[names(myData) == blockName] <- "BLOCK_NAME"
names(myData)[names(myData) == sessionID] <- "SESSION_ID"
names(myData)[names(myData) == trialLatency] <- "TRIAL_LATENCY"
myTbl <- group_by(tbl_df(myData), SESSION_ID)
myTbl$SUBEXCL <- 0
# Step 1: Include data from B3, B4, B6, B7
# Step 1 has been removed so all data is at least partially analyzed
# Step 2a: Eliminate trial latencies > 10,000ms and < 0ms
myTblNoLong <- filter(myTbl, TRIAL_LATENCY < 10000, TRIAL_LATENCY >= 0)
# Step 2b: Mark subjects for whom more than 10% of trials have latencies < 300ms with a 1
myFastTbl <- filter(myTbl, BLOCK_NAME %in% trialBlocks) %>%
summarise(FASTM = sum(TRIAL_LATENCY < 300)/length(TRIAL_LATENCY))
isTooFast <- filter(myFastTbl, FASTM > 0.10) %>%
select(SESSION_ID)
if(nrow(isTooFast) > 0){
myTbl[myTbl$SESSION_ID %in% isTooFast, ]$SUBEXCL <- 1
}
# Step 2c: Mark subjects with any missing blocks with a 2
numBlocks <- filter(myTbl, BLOCK_NAME %in% trialBlocks) %>%
summarise(total = length(unique(BLOCK_NAME)))
notComplete <- filter(numBlocks, total < 4)
if(nrow(notComplete) > 0){
myTbl[myTbl$SESSION_ID %in% notComplete, ]$SUBEXCL <- 2
}
# Step 3: Use all trials (in the conventional algorithm) the first two trials of each
# block would be dropped here
# Step 4: No extreme value treatment <or> delete trial with latencies < 400ms
if(vExtreme == 1){
myTblNotFast <- group_by(myTblNoLong, SESSION_ID, BLOCK_NAME)
} else if(vExtreme == 2){
myTblNotFast <- group_by(filter(myTblNoLong, TRIAL_LATENCY >= 400), SESSION_ID, BLOCK_NAME)
}
# Step 5: Compute mean of correct latencies for each block
# If vError = 1 then means and SDs will be calculated for the entire set of latencies
# IF vError = 2 then the algorithm will replace error trial latencies with blockmean + 600
# (where blockmean is mean of correct responses only)
# Step 5: Compute mean of correct latencies for each block
# If vError = 1 then means and SDs will be calculated for the entire set of latencies
# IF vError = 2 then the algorithm will replace error trial latencies with blockmean + 600
# (where blockmean is mean of correct responses only)
if(vError == 1){
blockMeans <- summarise(myTblNotFast, M = mean(TRIAL_LATENCY), N = length(TRIAL_LATENCY))
} else if(vError == 2){
meanReplace <- filter(myTblNotFast, TRIAL_ERROR == 0) %>%
summarise(blockMean = mean(TRIAL_LATENCY) + 600)
mergeTbl <- merge(myTblNotFast, meanReplace, by = c(sessionID, blockName), all = TRUE)
myTblNotFast$tmpLatency <- myTblNotFast$TRIAL_LATENCY
names(myTblNotFast)[c(14, 18)] <- c("oldLatency", trialLatency)
blockMeans <- summarise(myTblNotFast, M = mean(TRIAL_LATENCY), N = length(TRIAL_LATENCY))
} else stop("Please pick a value of 1 or 2 for vError.")
# Step 6: Compute pooled SD for B3 & B6, and separately for B4 & B7.
# If vStd is 1, the block SD is performed including error trials (corrected or not)
# If vStd is 2, the block SD is performed on correct responses only
myTblNotFast$blockPairs <- as.character(myTblNotFast$BLOCK_NAME)
myTblNotFast[myTblNotFast$BLOCK_NAME %in% trialBlocks[c(1,3)], ]$blockPairs <- "S1"
myTblNotFast[myTblNotFast$BLOCK_NAME %in% trialBlocks[c(2,4)], ]$blockPairs <- "S2"
myTblNotFast <- group_by(myTblNotFast, SESSION_ID, blockPairs)
allTblSDs <- merge(filter(myTblNotFast, BLOCK_NAME %in% trialBlocks) %>% summarise(A = sd(TRIAL_LATENCY)),
filter(myTblNotFast, BLOCK_NAME %in% trialBlocks & TRIAL_ERROR == 0) %>%
summarise(C = sd(TRIAL_LATENCY)),
by = c(sessionID, "blockPairs"))
blockMeansTbl <- merge(reshape(allTblSDs, v.names = c("A", "C"), idvar = "SESSION_ID", timevar = "blockPairs", direction = "wide", sep = ""),
reshape(blockMeans, v.names = c("M", "N"), idvar = "SESSION_ID", timevar = "BLOCK_NAME", direction = "wide", sep = ""),
by = "SESSION_ID")
# Step 7: Replace error latencies with block mean + 600ms
# Already done in step above
# Step 8: No transformation of latencies
# Step 9: Average latencies for each of the four blocks
# This was already done above
# Step 10: Compute the two differences B6 - B3 and B7 - B4
# Step 11: Divide each difference by associated pooled SD from step 6
if(vStd == 1){
tblResult <-
mutate(blockMeansTbl,
DIFF1 = MBLOCK5 - MBLOCK2,
DIFF2 = MBLOCK6 - MBLOCK3) %>%
mutate(IAT1 = DIFF1/AS1,
IAT2 = DIFF2/AS2) %>%
mutate(IAT = (IAT1 + IAT2)/2)
} else if(vStd == 2){
tblResult <-
mutate(blockMeansTbl,
DIFF1 = MBLOCK5 - MBLOCK2,
DIFF2 = MBLOCK6 - MBLOCK3) %>%
mutate(IAT1 = DIFF1/CS1,
IAT2 = DIFF2/CS2) %>%
mutate(IAT = (IAT1 + IAT2)/2)
} else stop("Please enter a vStd value of 1 or 2.")
##########################
# Create output dataframe
##########################
myTbl <- group_by(myTbl, SESSION_ID, BLOCK_NAME)
tblErrFast <- summarise(myTbl,
E = sum(TRIAL_ERROR)/length(TRIAL_ERROR),
F = sum(TRIAL_LATENCY < 300)/length(TRIAL_LATENCY))
tblErrFastWide <- reshape(tblErrFast, v.names = c("E", "F"), idvar = "SESSION_ID", timevar = "BLOCK_NAME", direction = "wide", sep = "")
tblExtras <- merge(tblErrFastWide, myFastTbl, by = sessionID, all = TRUE)
myTbl <- group_by(myTbl, SESSION_ID)
tblExcl <- summarise(myTbl, SUBEXCL = unique(SUBEXCL))
tblExtras$SUBEXCL <- tblExcl$SUBEXCL
tblTotal <- merge(tblResult, tblExtras, by = sessionID, all = TRUE)
}
fooFun(myData = myDataCongFirst,
blockName = "BLOCK_NAME_S",
trialBlocks = c("BLOCK2", "BLOCK3", "BLOCK5", "BLOCK6"),
sessionID = "SESSION_ID",
trialLatency = "TRIAL_LATENCY",
trialError = "TRIAL_ERROR",
vError = 1, vExtreme = 2, vStd = 1)
fooFun <- function(myData, sessionID, blockName, trialBlocks, trialLatency, trialError, vError, vExtreme, vStd){
names(myData)[names(myData) == blockName] <- "BLOCK_NAME"
names(myData)[names(myData) == sessionID] <- "SESSION_ID"
names(myData)[names(myData) == trialLatency] <- "TRIAL_LATENCY"
myTbl <- group_by(tbl_df(myData), SESSION_ID)
myTbl$SUBEXCL <- 0
# Step 1: Include data from B3, B4, B6, B7
# Step 1 has been removed so all data is at least partially analyzed
# Step 2a: Eliminate trial latencies > 10,000ms and < 0ms
myTblNoLong <- filter(myTbl, TRIAL_LATENCY < 10000, TRIAL_LATENCY >= 0)
# Step 2b: Mark subjects for whom more than 10% of trials have latencies < 300ms with a 1
myFastTbl <- filter(myTbl, BLOCK_NAME %in% trialBlocks) %>%
summarise(FASTM = sum(TRIAL_LATENCY < 300)/length(TRIAL_LATENCY))
isTooFast <- filter(myFastTbl, FASTM > 0.10) %>%
select(SESSION_ID)
if(nrow(isTooFast) > 0){
myTbl[myTbl$SESSION_ID %in% isTooFast, ]$SUBEXCL <- 1
}
# Step 2c: Mark subjects with any missing blocks with a 2
numBlocks <- filter(myTbl, BLOCK_NAME %in% trialBlocks) %>%
summarise(total = length(unique(BLOCK_NAME)))
notComplete <- filter(numBlocks, total < 4)
if(nrow(notComplete) > 0){
myTbl[myTbl$SESSION_ID %in% notComplete, ]$SUBEXCL <- 2
}
# Step 3: Use all trials (in the conventional algorithm) the first two trials of each
# block would be dropped here
# Step 4: No extreme value treatment <or> delete trial with latencies < 400ms
if(vExtreme == 1){
myTblNotFast <- group_by(myTblNoLong, SESSION_ID, BLOCK_NAME)
} else if(vExtreme == 2){
myTblNotFast <- group_by(filter(myTblNoLong, TRIAL_LATENCY >= 400), SESSION_ID, BLOCK_NAME)
}
# Step 5: Compute mean of correct latencies for each block
# If vError = 1 then means and SDs will be calculated for the entire set of latencies
# IF vError = 2 then the algorithm will replace error trial latencies with blockmean + 600
# (where blockmean is mean of correct responses only)
# Step 5: Compute mean of correct latencies for each block
# If vError = 1 then means and SDs will be calculated for the entire set of latencies
# IF vError = 2 then the algorithm will replace error trial latencies with blockmean + 600
# (where blockmean is mean of correct responses only)
if(vError == 1){
blockMeans <- summarise(myTblNotFast, M = mean(TRIAL_LATENCY), N = length(TRIAL_LATENCY))
} else if(vError == 2){
meanReplace <- filter(myTblNotFast, TRIAL_ERROR == 0) %>%
summarise(blockMean = mean(TRIAL_LATENCY) + 600)
mergeTbl <- merge(myTblNotFast, meanReplace, by = c(sessionID, blockName), all = TRUE)
myTblNotFast$tmpLatency <- myTblNotFast$TRIAL_LATENCY
names(myTblNotFast)[c(14, 18)] <- c("oldLatency", trialLatency)
blockMeans <- summarise(myTblNotFast, M = mean(TRIAL_LATENCY), N = length(TRIAL_LATENCY))
} else stop("Please pick a value of 1 or 2 for vError.")
# Step 6: Compute pooled SD for B3 & B6, and separately for B4 & B7.
# If vStd is 1, the block SD is performed including error trials (corrected or not)
# If vStd is 2, the block SD is performed on correct responses only
myTblNotFast$blockPairs <- as.character(myTblNotFast$BLOCK_NAME)
myTblNotFast[myTblNotFast$BLOCK_NAME %in% trialBlocks[c(1,3)], ]$blockPairs <- "S1"
myTblNotFast[myTblNotFast$BLOCK_NAME %in% trialBlocks[c(2,4)], ]$blockPairs <- "S2"
myTblNotFast <- group_by(myTblNotFast, SESSION_ID, blockPairs)
allTblSDs <- merge(filter(myTblNotFast, BLOCK_NAME %in% trialBlocks) %>% summarise(A = sd(TRIAL_LATENCY)),
filter(myTblNotFast, BLOCK_NAME %in% trialBlocks & TRIAL_ERROR == 0) %>%
summarise(C = sd(TRIAL_LATENCY)),
by = c(sessionID, "blockPairs"))
blockMeansTbl <- merge(reshape(allTblSDs, v.names = c("A", "C"), idvar = "SESSION_ID", timevar = "blockPairs", direction = "wide", sep = ""),
reshape(blockMeans, v.names = c("M", "N"), idvar = "SESSION_ID", timevar = "BLOCK_NAME", direction = "wide", sep = ""),
by = "SESSION_ID")
# Step 7: Replace error latencies with block mean + 600ms
# Already done in step above
# Step 8: No transformation of latencies
# Step 9: Average latencies for each of the four blocks
# This was already done above
# Step 10: Compute the two differences B6 - B3 and B7 - B4
# Step 11: Divide each difference by associated pooled SD from step 6
if(vStd == 1){
tblResult <-
mutate(blockMeansTbl,
DIFF1 = MBLOCK5 - MBLOCK2,
DIFF2 = MBLOCK6 - MBLOCK3) %>%
mutate(IAT1 = DIFF1/AS1,
IAT2 = DIFF2/AS2) %>%
mutate(IAT = (IAT1 + IAT2)/2)
} else if(vStd == 2){
tblResult <-
mutate(blockMeansTbl,
DIFF1 = MBLOCK5 - MBLOCK2,
DIFF2 = MBLOCK6 - MBLOCK3) %>%
mutate(IAT1 = DIFF1/CS1,
IAT2 = DIFF2/CS2) %>%
mutate(IAT = (IAT1 + IAT2)/2)
} else stop("Please enter a vStd value of 1 or 2.")
##########################
# Create output dataframe
##########################
myTbl <- group_by(myTbl, SESSION_ID, BLOCK_NAME)
tblErrFast <- summarise(myTbl,
E = sum(TRIAL_ERROR)/length(TRIAL_ERROR),
F = sum(TRIAL_LATENCY < 300)/length(TRIAL_LATENCY))
tblErrFastWide <- reshape(tblErrFast, v.names = c("E", "F"), idvar = "SESSION_ID", timevar = "BLOCK_NAME", direction = "wide", sep = "")
tblExtras <- merge(tblErrFastWide, myFastTbl, by = sessionID, all = TRUE)
myTbl <- group_by(myTbl, SESSION_ID)
tblExcl <- summarise(myTbl, SUBEXCL = unique(SUBEXCL))
tblExtras$SUBEXCL <- tblExcl$SUBEXCL
tblTotal <- merge(tblResult, tblExtras, by = sessionID, all = TRUE)
return(tblTotal)
}
fooFun(myData = myDataCongFirst,
blockName = "BLOCK_NAME_S",
trialBlocks = c("BLOCK2", "BLOCK3", "BLOCK5", "BLOCK6"),
sessionID = "SESSION_ID",
trialLatency = "TRIAL_LATENCY",
trialError = "TRIAL_ERROR",
vError = 1, vExtreme = 2, vStd = 1)
benchmark(gah <- fooFun(myData = myDataCongFirst,
blockName = "BLOCK_NAME_S",
trialBlocks = c("BLOCK2", "BLOCK3", "BLOCK5", "BLOCK6"),
sessionID = "SESSION_ID",
trialLatency = "TRIAL_LATENCY",
trialError = "TRIAL_ERROR",
vError = 1, vExtreme = 2, vStd = 1))
myData = myDataCongFirst;
blockName = "BLOCK_NAME_S";
trialBlocks = c("BLOCK2", "BLOCK3", "BLOCK5", "BLOCK6");
sessionID = "SESSION_ID";
trialLatency <- 'TRIAL_LATENCY';
trialError = "TRIAL_ERROR";
vError = 1; vExtreme = 2; vStd = 1
names(myData)[names(myData) == blockName] <- "BLOCK_NAME"
names(myData)[names(myData) == sessionID] <- "SESSION_ID"
names(myData)[names(myData) == trialLatency] <- "TRIAL_LATENCY"
myTbl <- group_by(tbl_df(myData), SESSION_ID)
myTbl$SUBEXCL <- 0
# Step 1: Include data from B3, B4, B6, B7
# Step 1 has been removed so all data is at least partially analyzed
# Step 2a: Eliminate trial latencies > 10,000ms and < 0ms
myTblNoLong <- filter(myTbl, TRIAL_LATENCY < 10000, TRIAL_LATENCY >= 0)
# Step 2b: Mark subjects for whom more than 10% of trials have latencies < 300ms with a 1
myFastTbl <- filter(myTbl, BLOCK_NAME %in% trialBlocks) %>%
summarise(FASTM = sum(TRIAL_LATENCY < 300)/length(TRIAL_LATENCY))
isTooFast <- filter(myFastTbl, FASTM > 0.10) %>%
select(SESSION_ID)
if(nrow(isTooFast) > 0){
myTbl[myTbl$SESSION_ID %in% isTooFast, ]$SUBEXCL <- 1
}
# Step 2c: Mark subjects with any missing blocks with a 2
numBlocks <- filter(myTbl, BLOCK_NAME %in% trialBlocks) %>%
summarise(total = length(unique(BLOCK_NAME)))
notComplete <- filter(numBlocks, total < 4)
if(nrow(notComplete) > 0){
myTbl[myTbl$SESSION_ID %in% notComplete, ]$SUBEXCL <- 2
}
# Step 3: Use all trials (in the conventional algorithm) the first two trials of each
# block would be dropped here
# Step 4: No extreme value treatment <or> delete trial with latencies < 400ms
if(vExtreme == 1){
myTblNotFast <- group_by(myTblNoLong, SESSION_ID, BLOCK_NAME)
} else if(vExtreme == 2){
myTblNotFast <- group_by(filter(myTblNoLong, TRIAL_LATENCY >= 400), SESSION_ID, BLOCK_NAME)
}
# Step 5: Compute mean of correct latencies for each block
# If vError = 1 then means and SDs will be calculated for the entire set of latencies
# IF vError = 2 then the algorithm will replace error trial latencies with blockmean + 600
# (where blockmean is mean of correct responses only)
# Step 5: Compute mean of correct latencies for each block
# If vError = 1 then means and SDs will be calculated for the entire set of latencies
# IF vError = 2 then the algorithm will replace error trial latencies with blockmean + 600
# (where blockmean is mean of correct responses only)
if(vError == 1){
blockMeans <- summarise(myTblNotFast, M = mean(TRIAL_LATENCY), N = length(TRIAL_LATENCY))
} else if(vError == 2){
meanReplace <- filter(myTblNotFast, TRIAL_ERROR == 0) %>%
summarise(blockMean = mean(TRIAL_LATENCY) + 600)
mergeTbl <- merge(myTblNotFast, meanReplace, by = c(sessionID, blockName), all = TRUE)
myTblNotFast$tmpLatency <- myTblNotFast$TRIAL_LATENCY
names(myTblNotFast)[c(14, 18)] <- c("oldLatency", trialLatency)
blockMeans <- summarise(myTblNotFast, M = mean(TRIAL_LATENCY), N = length(TRIAL_LATENCY))
} else stop("Please pick a value of 1 or 2 for vError.")
# Step 6: Compute pooled SD for B3 & B6, and separately for B4 & B7.
# If vStd is 1, the block SD is performed including error trials (corrected or not)
# If vStd is 2, the block SD is performed on correct responses only
myTblNotFast$blockPairs <- as.character(myTblNotFast$BLOCK_NAME)
myTblNotFast[myTblNotFast$BLOCK_NAME %in% trialBlocks[c(1,3)], ]$blockPairs <- "S1"
myTblNotFast[myTblNotFast$BLOCK_NAME %in% trialBlocks[c(2,4)], ]$blockPairs <- "S2"
myTblNotFast <- group_by(myTblNotFast, SESSION_ID, blockPairs)
allTblSDs <- merge(filter(myTblNotFast, BLOCK_NAME %in% trialBlocks) %>% summarise(A = sd(TRIAL_LATENCY)),
filter(myTblNotFast, BLOCK_NAME %in% trialBlocks & TRIAL_ERROR == 0) %>%
summarise(C = sd(TRIAL_LATENCY)),
by = c(sessionID, "blockPairs"))
blockMeansTbl <- merge(reshape(allTblSDs, v.names = c("A", "C"), idvar = "SESSION_ID", timevar = "blockPairs", direction = "wide", sep = ""),
reshape(blockMeans, v.names = c("M", "N"), idvar = "SESSION_ID", timevar = "BLOCK_NAME", direction = "wide", sep = ""),
by = "SESSION_ID")
# Step 7: Replace error latencies with block mean + 600ms
# Already done in step above
# Step 8: No transformation of latencies
# Step 9: Average latencies for each of the four blocks
# This was already done above
# Step 10: Compute the two differences B6 - B3 and B7 - B4
# Step 11: Divide each difference by associated pooled SD from step 6
if(vStd == 1){
tblResult <-
mutate(blockMeansTbl,
DIFF1 = MBLOCK5 - MBLOCK2,
DIFF2 = MBLOCK6 - MBLOCK3) %>%
mutate(IAT1 = DIFF1/AS1,
IAT2 = DIFF2/AS2) %>%
mutate(IAT = (IAT1 + IAT2)/2)
} else if(vStd == 2){
tblResult <-
mutate(blockMeansTbl,
DIFF1 = MBLOCK5 - MBLOCK2,
DIFF2 = MBLOCK6 - MBLOCK3) %>%
mutate(IAT1 = DIFF1/CS1,
IAT2 = DIFF2/CS2) %>%
mutate(IAT = (IAT1 + IAT2)/2)
} else stop("Please enter a vStd value of 1 or 2.")
##########################
# Create output dataframe
##########################
myTbl <- group_by(myTbl, SESSION_ID, BLOCK_NAME)
tblErrFast <- summarise(myTbl,
E = sum(TRIAL_ERROR)/length(TRIAL_ERROR),
F = sum(TRIAL_LATENCY < 300)/length(TRIAL_LATENCY))
tblErrFastWide <- reshape(tblErrFast, v.names = c("E", "F"), idvar = "SESSION_ID", timevar = "BLOCK_NAME", direction = "wide", sep = "")
tblExtras <- merge(tblErrFastWide, myFastTbl, by = sessionID, all = TRUE)
myTbl <- group_by(myTbl, SESSION_ID)
tblExcl <- summarise(myTbl, SUBEXCL = unique(SUBEXCL))
tblExtras$SUBEXCL <- tblExcl$SUBEXCL
tblTotal <- merge(tblResult, tblExtras, by = sessionID, all = TRUE)
tblTotal
names(tblTotal)
names(tblTotal)[names(myData) == "SESSION_ID"]
names(tblTotal)[names(tblTotal) == "SESSION_ID"]
sessionID
data("IATData.rdata", envir = .BaseNamespaceEnv)
library(IAT)
?last
data("IATData.rdata", envir = .BaseNamespaceEnv)
data("Data/IATData.rdata", envir = .BaseNamespaceEnv)
list.files()
data("data/IATData.rdata", envir = .BaseNamespaceEnv)
list.files("data")
load("IATData.rdata")
load("data/IATData.rdata")
ls()
myData <- IATDatals()
myData <- IATData
length(unique(myData[, sessionID])) > 100
?cleanIAT
myData = myDataCongFirst
blockName = "BLOCK_NAME_S"
trialBlocks = c("BLOCK2", "BLOCK3", "BLOCK5", "BLOCK6")
sessionID = "SESSION_ID"
trialLatency = "TRIAL_LATENCY"
trialError = "TRIAL_ERROR"
vError = 1
vExtreme = 2
vStd = 1
length(unique(myData[, sessionID])) > 100
sampleIDs <- sample(unique(myData[, sessionID]), 100)
if(length(unique(myData[, sessionID])) > 100){
sampleIDs <- sample(unique(myData[, sessionID]), 100)
myData <- myData[myData[, sessionID] %in% sampleIDs, ]
warning("Your total sample size is > 100. A random subsample was taken for plotting.")
}
myDataNew <- myData[myData[, blockName] %in% trialBlocks, ]
myDataNew <- myDataNew[myDataNew[, trialLatency] > 180 & myDataNew[, trialLatency] < 10000, ]
myDataCongFirst <- IATData[IATData$isCongruentFirst == 1, ]
myData = myDataCongFirst
blockName = "BLOCK_NAME_S"
trialBlocks = c("BLOCK2", "BLOCK3", "BLOCK5", "BLOCK6")
sessionID = "SESSION_ID"
trialLatency = "TRIAL_LATENCY"
trialError = "TRIAL_ERROR"
vError = 1
vExtreme = 2
vStd = 1
myTbl <- tbl_df(myData)
require(dplyr)
myTbl <- tbl_df(myData)
myTbl
myTbl <- group_by(tbl_df(myData), SESSION_ID)
myTbl
byPart <- filter(myTbl, TRIAL_LATENCY > 180 & TRIAL_LATENCY < 10000, TRIAL_ERROR == 0, BLOCK_NAME %in% TRIAL_BLOCKS) %>%
summarise(N = length(TRIAL_LATENCY),
meanRT = mean(TRIAL_LATENCY),
mySD = sd(TRIAL_LATENCY),
mySE = sd(TRIAL_LATENCY)/sqrt(length(TRIAL_LATENCY)))
names(myData)[names(myData) == trialLatency] <- "TRIAL_LATENCY"
names(myData)[names(myData) == trialError] <- "TRIAL_ERROR"
names(myData)[names(myData) == blockName] <- "BLOCK_NAME"
names(myData)[names(myData) == sessionID] <- "SESSION_ID"
byPart <- filter(myTbl, TRIAL_LATENCY > 180 & TRIAL_LATENCY < 10000, TRIAL_ERROR == 0, BLOCK_NAME %in% TRIAL_BLOCKS) %>%
summarise(N = length(TRIAL_LATENCY),
meanRT = mean(TRIAL_LATENCY),
mySD = sd(TRIAL_LATENCY),
mySE = sd(TRIAL_LATENCY)/sqrt(length(TRIAL_LATENCY)))
myDataCongFirst <- IATData[IATData$isCongruentFirst == 1, ]
myData = myDataCongFirst
blockName = "BLOCK_NAME_S"
trialBlocks = c("BLOCK2", "BLOCK3", "BLOCK5", "BLOCK6")
sessionID = "SESSION_ID"
trialLatency = "TRIAL_LATENCY"
trialError = "TRIAL_ERROR"
vError = 1
vExtreme = 2
vStd = 1
names(myData)[names(myData) == trialLatency] <- "TRIAL_LATENCY"
names(myData)[names(myData) == trialError] <- "TRIAL_ERROR"
names(myData)[names(myData) == blockName] <- "BLOCK_NAME"
names(myData)[names(myData) == sessionID] <- "SESSION_ID"
myTbl <- group_by(tbl_df(myData), SESSION_ID)
myTbl
byPart <- filter(myTbl, TRIAL_LATENCY > 180 & TRIAL_LATENCY < 10000, TRIAL_ERROR == 0, BLOCK_NAME %in% trialBlocks) %>%
summarise(N = length(TRIAL_LATENCY),
meanRT = mean(TRIAL_LATENCY),
mySD = sd(TRIAL_LATENCY),
mySE = sd(TRIAL_LATENCY)/sqrt(length(TRIAL_LATENCY)))
byPart
byPart$SESSION_ID <- factor(byPart$SESSION_ID, levels = byPart[order(byPart$meanRT),]$SESSION_ID)
p <- ggplot(byPart, aes(x = SESSION_ID, y = meanRT)) + geom_errorbar(aes(ymin = meanRT - 2*mySE, ymax = meanRT + 2*mySE), width = 0)
require(ggplot2)
p <- ggplot(byPart, aes(x = SESSION_ID, y = meanRT)) + geom_errorbar(aes(ymin = meanRT - 2*mySE, ymax = meanRT + 2*mySE), width = 0)
p <- p + geom_line() + geom_point() + coord_flip() + theme_bw()
suppressMessages(print(p))
p <- p + geom_line() + geom_point() + coord_flip() + theme_bw() + labs(x = "Session ID", y = "Mean Reaction Time")
suppressMessages(print(p))
names(myData)[names(myData) == trialLatency] <- "TRIAL_LATENCY"
names(myData)[names(myData) == trialError] <- "TRIAL_ERROR"
names(myData)[names(myData) == sessionID] <- "SESSION_ID"
myTbl <- group_by(tbl_df(myData), SESSION_ID)
byPart <- filter(myTbl, TRIAL_LATENCY > 180 & TRIAL_LATENCY < 10000) %>%
summarise(propErrors = sum(TRIAL_ERROR == 1)/length(TRIAL_ERROR))
byItemErr$itemName <- factor(byItemErr$itemName, levels = byItemErr[order(byItemErr$propErrors),]$itemName)
byItemErr <- filter(myTbl, TRIAL_LATENCY > 180 & TRIAL_LATENCY < 10000) %>%
summarise(propErrors = sum(TRIAL_ERROR == 1)/length(TRIAL_ERROR))
byItemErr$itemName <- factor(byItemErr$itemName, levels = byItemErr[order(byItemErr$propErrors),]$itemName)
byItemErr
myMean <- mean(byItemErr$propErrors)
myMean
p <- ggplot(byItemErr, aes(x = itemName, y = propErrors)) + geom_bar(fill = "dark gray", stat = "identity") + geom_hline(aes(yintercept = mean(propErrors)), size = 1.5)
p <- p + coord_flip() + theme_bw()
suppressMessages(suppressWarnings(print(p)))
byItemErr
byItemErr$itemName <- factor(byItemErr$itemName, levels = byItemErr[order(byItemErr$propErrors),]$itemName)
byItemErr$itemName
itemName
myData
myTbl
itemName <- "TRIAL_NAME_S"
byItemErr$itemName <- factor(byItemErr$itemName, levels = byItemErr[order(byItemErr$propErrors),]$itemName)
byItemErr$itemName
itemName
byItemErr$itemName <- factor(byItemErr[, itemName], levels = byItemErr[order(byItemErr$propErrors),][, itemName])
byItemErr[, itemName]
byItemErr <- filter(myTbl, TRIAL_LATENCY > 180 & TRIAL_LATENCY < 10000) %>%
summarise(propErrors = sum(TRIAL_ERROR == 1)/length(TRIAL_ERROR))
byItemErr
names(myData)[names(myData) == itemName] <- "ITEM"
myTbl <- group_by(tbl_df(myData), ITEM)
byItemErr <- filter(myTbl, TRIAL_LATENCY > 180 & TRIAL_LATENCY < 10000) %>%
summarise(propErrors = sum(TRIAL_ERROR == 1)/length(TRIAL_ERROR))
byItemErr$itemName <- factor(byItemErr$ITEM, levels = byItemErr[order(byItemErr$propErrors),]$ITEM)
byItemErr
names(myData)[names(myData) == trialLatency] <- "TRIAL_LATENCY"
names(myData)[names(myData) == trialError] <- "TRIAL_ERROR"
names(myData)[names(myData) == sessionID] <- "SESSION_ID"
names(myData)[names(myData) == itemName] <- "ITEM"
myTbl <- group_by(tbl_df(myData), ITEM)
byItemErr <- filter(myTbl, TRIAL_LATENCY > 180 & TRIAL_LATENCY < 10000) %>%
summarise(propErrors = sum(TRIAL_ERROR == 1)/length(TRIAL_ERROR))
byItemErr
byItemErr$ITEM <- factor(byItemErr$ITEM, levels = byItemErr[order(byItemErr$propErrors),]$ITEM)
byItemErr
myMean <- mean(byItemErr$propErrors)
p <- ggplot(byItemErr, aes(x = ITEM, y = propErrors)) + geom_bar(fill = "dark gray", stat = "identity")
p <- p + geom_hline(aes(yintercept = mean(propErrors)), size = 1.5)
p <- p + coord_flip() + theme_bw()
suppressMessages(suppressWarnings(print(p)))
myTbl <- group_by(tbl_df(myData), ITEM)
byItem <- filter(myTbl, TRIAL_LATENCY > 180 & TRIAL_LATENCY < 10000, TRIAL_ERROR == 0, BLOCK_NAME %in% trialBlocks) %>%
summarise(N = length(TRIAL_LATENCY),
meanRT = mean(TRIAL_LATENCY),
mySD = sd(TRIAL_LATENCY),
mySE = sd(TRIAL_LATENCY)/sqrt(length(TRIAL_LATENCY)))
byItem$ITEM <- factor(byItem$ITEM, levels = byItem[order(byItem$meanRT), ]$ITEM)
p <- ggplot(byItem, aes(x = ITEM, y = meanRT)) + geom_errorbar(aes(ymin = meanRT - 2*mySE, ymax = meanRT + 2*mySE), width = 0)
p <- p + geom_line() + geom_point() + coord_flip() + theme_bw()
suppressMessages(print(p))
p <- p + geom_line() + geom_point() + coord_flip() + theme_bw() + labs(x = "Item", y = "Mean Reaction Time")
suppressMessages(print(p))
library(IAT)
p <- ggplot(byPart, aes_string(x = "SESSION_ID", y = "meanRT")) + geom_errorbar(aes(ymin = meanRT - 2*mySE, ymax = meanRT + 2*mySE), width = 0)
p <- p + geom_line() + geom_point() + coord_flip() + theme_bw() + labs(x = "Session ID", y = "Mean Reaction Time")
suppressMessages(print(p))
options(repos = c(CRAN="http://cran.r-project.org"))
library(IAT)
IATData
rm(list = ls())
library(IAT)
head(IATData)
library(IAT)
